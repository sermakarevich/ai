{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an extensive summary in markdown format, drawing on the provided sources, our conversation history, and with some bolding to highlight key concepts:\n",
    "\n",
    "**Structured Output from Language Models in LangChain**\n",
    "\n",
    "*   **Purpose:** This guide focuses on methods for getting structured outputs from language models (LLMs), which is often needed for tasks such as extracting data to insert into a database or use in a downstream system.\n",
    "*   **Key Methods:** There are multiple ways to achieve structured output, including using the `.with_structured_output()` method, and by directly prompting and parsing model outputs.\n",
    "*  **Prerequisites:** Familiarity with chat models and function/tool calling is recommended before using these techniques.\n",
    "\n",
    "**The `.with_structured_output()` Method**\n",
    "\n",
    "*   **Supported Models:** This method is available for models that have native APIs for structuring outputs, like tool/function calling or JSON mode.\n",
    "*   **Schema Input:** This method requires a schema that specifies the names, types, and descriptions of the desired output attributes. The schema can be a `TypedDict` class, a JSON Schema, or a Pydantic class.\n",
    "    *   **TypedDict/JSON Schema**: When using `TypedDict` or JSON Schema, the method returns a dictionary.\n",
    "    *   **Pydantic Class:** When using a Pydantic class, the method returns a Pydantic object.\n",
    "*   **Validation:** A key advantage of using Pydantic is that the model-generated output will be validated. Pydantic will raise an error if required fields are missing or of the wrong type.\n",
    "\n",
    "**Using Pydantic Classes**\n",
    "\n",
    "*   **Defining the Schema:** Define the desired structure using a Pydantic class, including field names, types, and descriptions. The class name, docstring, and parameter descriptions are important, as this information is added to the model prompt.\n",
    "*   **Example:**\n",
    "    ```python\n",
    "    from typing import Optional\n",
    "    from pydantic import BaseModel, Field\n",
    "\n",
    "    class Joke(BaseModel):\n",
    "        \"\"\"Joke to tell user.\"\"\"\n",
    "        setup: str = Field(description=\"The setup of the joke\")\n",
    "        punchline: str = Field(description=\"The punchline to the joke\")\n",
    "        rating: Optional[int] = Field(default=None, description=\"How funny the joke is, from 1 to 10\")\n",
    "    ```\n",
    "*   **Usage:**\n",
    "    ```python\n",
    "    structured_llm = llm.with_structured_output(Joke)\n",
    "    structured_llm.invoke(\"Tell me a joke about cats\")\n",
    "    ```\n",
    "\n",
    "**Using TypedDict or JSON Schema**\n",
    "\n",
    "*   **TypedDict:** Use `TypedDict` if you don't want Pydantic's validation or want to stream outputs. You can optionally use the `Annotated` syntax to specify default values and descriptions.\n",
    "*   **JSON Schema:** A JSON Schema dictionary can also define the structure. This is more verbose but makes it very clear how each parameter is documented.\n",
    "*   **Example (TypedDict):**\n",
    "    ```python\n",
    "    from typing_extensions import Annotated, TypedDict\n",
    "    from typing import Optional\n",
    "\n",
    "    class Joke(TypedDict):\n",
    "        \"\"\"Joke to tell user.\"\"\"\n",
    "        setup: Annotated[str, ..., \"The setup of the joke\"]\n",
    "        punchline: Annotated[str, ..., \"The punchline of the joke\"]\n",
    "        rating: Annotated[Optional[int], None, \"How funny the joke is, from 1 to 10\"]\n",
    "    ```\n",
    "*   **Example (JSON Schema):**\n",
    "    ```python\n",
    "    json_schema = {\n",
    "        \"title\": \"joke\",\n",
    "        \"description\": \"Joke to tell user.\",\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"setup\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The setup of the joke\",\n",
    "            },\n",
    "            \"punchline\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The punchline to the joke\",\n",
    "            },\n",
    "            \"rating\": {\n",
    "                \"type\": \"integer\",\n",
    "                \"description\": \"How funny the joke is, from 1 to 10\",\n",
    "                \"default\": None,\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"setup\", \"punchline\"],\n",
    "    }\n",
    "    ```\n",
    "\n",
    "**Choosing Between Multiple Schemas**\n",
    "\n",
    "*   **Union-Typed Attribute:** You can let the model choose between multiple schemas by creating a parent schema with a `Union`-typed attribute.\n",
    "*   **Example:**\n",
    "    ```python\n",
    "    from typing import Union\n",
    "    from pydantic import BaseModel, Field\n",
    "\n",
    "    class Joke(BaseModel):\n",
    "        \"\"\"Joke to tell user.\"\"\"\n",
    "        setup: str = Field(description=\"The setup of the joke\")\n",
    "        punchline: str = Field(description=\"The punchline to the joke\")\n",
    "        rating: Optional[int] = Field(default=None, description=\"How funny the joke is, from 1 to 10\")\n",
    "\n",
    "    class ConversationalResponse(BaseModel):\n",
    "        \"\"\"Respond in a conversational manner. Be kind and helpful.\"\"\"\n",
    "        response: str = Field(description=\"A conversational response to the user's query\")\n",
    "\n",
    "    class FinalResponse(BaseModel):\n",
    "        final_output: Union[Joke, ConversationalResponse]\n",
    "    ```\n",
    "\n",
    "**Streaming**\n",
    "\n",
    "*   **Supported Types:** Streaming is supported when the output type is a dictionary (i.e., when the schema is specified as a `TypedDict` class or JSON Schema dictionary).\n",
    "*   **Output:** Streaming yields aggregated chunks, not deltas.\n",
    "\n",
    "**Few-Shot Prompting**\n",
    "\n",
    "*   **Examples in System Message:** You can add examples to a system message to guide the model, especially for complex schemas.\n",
    "*   **Examples as Tool Calls:**  If the model uses tool calling, you can pass examples as explicit tool calls. This can sometimes lead to better performance.\n",
    "\n",
    "**Advanced Options**\n",
    "\n",
    "*   **Specifying Method:** For models supporting multiple output structuring methods, you can specify which method to use (e.g., `method=\"json_mode\"`).\n",
    "*   **Raw Outputs:** By using `include_raw=True`, you can access the raw model output, parsed value, and any errors, allowing you to handle parsing failures.\n",
    "\n",
    "**Prompting and Parsing Model Outputs Directly**\n",
    "\n",
    "*   **When to Use:** For models that do not support `.with_structured_output()`, or when you need more control, you can directly prompt the model to use a specific format and use an output parser.\n",
    "*   **PydanticOutputParser:** This built-in parser can parse model outputs that match a Pydantic schema. It can add formatting instructions directly to the prompt.\n",
    "    *   **Example:**\n",
    "        ```python\n",
    "        from langchain_core.output_parsers import PydanticOutputParser\n",
    "        from langchain_core.prompts import ChatPromptTemplate\n",
    "        from pydantic import BaseModel, Field\n",
    "        class Person(BaseModel):\n",
    "            \"\"\"Information about a person.\"\"\"\n",
    "            name: str = Field(..., description=\"The name of the person\")\n",
    "            height_in_meters: float = Field(..., description=\"The height of the person expressed in meters.\")\n",
    "        class People(BaseModel):\n",
    "            \"\"\"Identifying information about all people in a text.\"\"\"\n",
    "            people: List[Person]\n",
    "        parser = PydanticOutputParser(pydantic_object=People)\n",
    "        prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"Answer the user query. Wrap the output in `json` tags\\n{format_instructions}\"),\n",
    "            (\"human\", \"{query}\"),\n",
    "        ]).partial(format_instructions=parser.get_format_instructions())\n",
    "        ```\n",
    "*  **Custom Parsing:** You can also create custom prompts and parsers using LangChain Expression Language (LCEL) and plain functions to parse the output from the model.\n",
    "    *  **Example:**\n",
    "        ```python\n",
    "        import json\n",
    "        import re\n",
    "        from langchain_core.messages import AIMessage\n",
    "        def extract_json(message: AIMessage) -> List[dict]:\n",
    "            text = message.content\n",
    "            pattern = r\"\\`\\`\\`json(.*?)\\`\\`\\`\"\n",
    "            matches = re.findall(pattern, text, re.DOTALL)\n",
    "            try:\n",
    "                return [json.loads(match.strip()) for match in matches]\n",
    "            except Exception:\n",
    "                raise ValueError(f\"Failed to parse: {message}\")\n",
    "        ```\n",
    "\n",
    "**Key Takeaways**\n",
    "\n",
    "*   The `.with_structured_output()` method is the easiest way to get structured outputs, for models that support it.\n",
    "*   Pydantic classes provide data validation, while TypedDict and JSON Schema offer flexibility and streaming options.\n",
    "*   Few-shot prompting is crucial for complex schemas, especially when using tool calling.\n",
    "*   For models without native structured output support, you can use output parsers or create a custom solution.\n",
    "*   For complex situations with models that may not perfectly adhere to format instructions, using raw outputs (`include_raw=True`) can enable more robust output handling and error processing.\n",
    "\n",
    "This summary provides a comprehensive overview of how to return structured data from language models using LangChain, covering different approaches, their advantages, and use cases, drawing on the information in the provided sources.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Joke(setup='Why was the cat sitting on the computer?', punchline='Because it wanted to keep an eye on the mouse!', rating=8)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Optional\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "# Pydantic\n",
    "class Joke(BaseModel):\n",
    "    \"\"\"Joke to tell user.\"\"\"\n",
    "\n",
    "    setup: str = Field(description=\"The setup of the joke\")\n",
    "    punchline: str = Field(description=\"The punchline to the joke\")\n",
    "    rating: Optional[int] = Field(\n",
    "        default=None, description=\"How funny the joke is, from 1 to 10\"\n",
    "    )\n",
    "\n",
    "\n",
    "structured_llm = llm.with_structured_output(Joke)\n",
    "\n",
    "structured_llm.invoke(\"Tell me a joke about cats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'setup': 'Why did the dog sit in the shade?',\n",
       " 'punchline': \"Because he didn't want to become a hot dog!\",\n",
       " 'rating': 7}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing_extensions import Annotated, TypedDict\n",
    "\n",
    "\n",
    "# TypedDict\n",
    "class Joke(TypedDict):\n",
    "    \"\"\"Joke to tell user.\"\"\"\n",
    "\n",
    "    setup: Annotated[str, ..., \"The setup of the joke\"]\n",
    "\n",
    "    # Alternatively, we could have specified setup as:\n",
    "\n",
    "    # setup: str                    # no default, no description\n",
    "    # setup: Annotated[str, ...]    # no default, no description\n",
    "    # setup: Annotated[str, \"foo\"]  # default, no description\n",
    "\n",
    "    punchline: Annotated[str, ..., \"The punchline of the joke\"]\n",
    "    rating: Annotated[Optional[int], None, \"How funny the joke is, from 1 to 10\"]\n",
    "\n",
    "\n",
    "structured_llm = llm.with_structured_output(Joke)\n",
    "\n",
    "structured_llm.invoke(\"Tell me a joke about a dog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'setup': 'Why did the sun go to school?',\n",
       " 'punchline': 'To get a little brighter!',\n",
       " 'rating': 7}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_schema = {\n",
    "    \"title\": \"joke\",\n",
    "    \"description\": \"Joke to tell user.\",\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"setup\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The setup of the joke\",\n",
    "        },\n",
    "        \"punchline\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The punchline to the joke\",\n",
    "        },\n",
    "        \"rating\": {\n",
    "            \"type\": \"integer\",\n",
    "            \"description\": \"How funny the joke is, from 1 to 10\",\n",
    "            \"default\": None,\n",
    "        },\n",
    "    },\n",
    "    \"required\": [\"setup\", \"punchline\"],\n",
    "}\n",
    "structured_llm = llm.with_structured_output(json_schema)\n",
    "\n",
    "structured_llm.invoke(\"Tell me a joke about a space\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FinalResponse(final_output=Joke(setup='Why did the job seeker bring a ladder to the interview?', punchline='Because they heard the job was at a higher level!', rating=7))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The simplest way to let the model choose from multiple schemas is to create a parent schema that has a Union-typed attribute.\n",
    "\n",
    "from typing import Union\n",
    "\n",
    "\n",
    "class Joke(BaseModel):\n",
    "    \"\"\"Joke to tell user.\"\"\"\n",
    "\n",
    "    setup: str = Field(description=\"The setup of the joke\")\n",
    "    punchline: str = Field(description=\"The punchline to the joke\")\n",
    "    rating: Optional[int] = Field(\n",
    "        default=None, description=\"How funny the joke is, from 1 to 10\"\n",
    "    )\n",
    "\n",
    "\n",
    "class ConversationalResponse(BaseModel):\n",
    "    \"\"\"Respond in a conversational manner. Be kind and helpful.\"\"\"\n",
    "\n",
    "    response: str = Field(description=\"A conversational response to the user's query\")\n",
    "\n",
    "\n",
    "class FinalResponse(BaseModel):\n",
    "    final_output: Union[Joke, ConversationalResponse]\n",
    "\n",
    "\n",
    "structured_llm = llm.with_structured_output(FinalResponse)\n",
    "\n",
    "structured_llm.invoke(\"Tell me a joke about job serach process\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FinalResponse(final_output=ConversationalResponse(response=\"I'm just a bunch of code, but I'm here and ready to help you! How about you? How's your day going?\"))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structured_llm.invoke(\"How are you today?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Joke(setup='Why did the job seeker bring a ladder to the interview?', punchline='Because they wanted to reach their career goals!', rating=8)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "ollama = ChatOllama(model='llama3.1')\n",
    "\n",
    "structured_ollama = ollama.with_structured_output(Joke)\n",
    "structured_ollama.invoke(\"Tell me a joke about job serach process\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'punchline': 'Why did the cat join a band? Because it wanted to be the purr-cussionist!', 'rating': 8, 'setup': 'A cat decided to audition for a band and had to choose an instrument.'}\n"
     ]
    }
   ],
   "source": [
    "from typing_extensions import Annotated, TypedDict\n",
    "\n",
    "\n",
    "# TypedDict\n",
    "class Joke(TypedDict):\n",
    "    \"\"\"Joke to tell user.\"\"\"\n",
    "\n",
    "    setup: Annotated[str, ..., \"The setup of the joke\"]\n",
    "    punchline: Annotated[str, ..., \"The punchline of the joke\"]\n",
    "    rating: Annotated[Optional[int], None, \"How funny the joke is, from 1 to 10\"]\n",
    "\n",
    "\n",
    "structured_ollama = ollama.with_structured_output(Joke)\n",
    "\n",
    "for chunk in structured_ollama.stream(\"Tell me a joke about cats\"):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why\n",
      " did\n",
      " the\n",
      " cat\n",
      " join\n",
      " a\n",
      " band\n",
      "?\n",
      "\n",
      "\n",
      "Because\n",
      " it\n",
      " wanted\n",
      " to\n",
      " be\n",
      " the\n",
      " pur\n",
      "r\n",
      "-c\n",
      "ussion\n",
      "ist\n",
      ".\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for chunk in ollama.stream(\"Tell me a joke about cats\"):\n",
    "    print(chunk.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "{'setup': ''}\n",
      "{'setup': 'Why'}\n",
      "{'setup': 'Why was'}\n",
      "{'setup': 'Why was the'}\n",
      "{'setup': 'Why was the cat'}\n",
      "{'setup': 'Why was the cat sitting'}\n",
      "{'setup': 'Why was the cat sitting on'}\n",
      "{'setup': 'Why was the cat sitting on the'}\n",
      "{'setup': 'Why was the cat sitting on the computer'}\n",
      "{'setup': 'Why was the cat sitting on the computer?'}\n",
      "{'setup': 'Why was the cat sitting on the computer?', 'punchline': ''}\n",
      "{'setup': 'Why was the cat sitting on the computer?', 'punchline': 'Because'}\n",
      "{'setup': 'Why was the cat sitting on the computer?', 'punchline': 'Because it'}\n",
      "{'setup': 'Why was the cat sitting on the computer?', 'punchline': 'Because it wanted'}\n",
      "{'setup': 'Why was the cat sitting on the computer?', 'punchline': 'Because it wanted to'}\n",
      "{'setup': 'Why was the cat sitting on the computer?', 'punchline': 'Because it wanted to keep'}\n",
      "{'setup': 'Why was the cat sitting on the computer?', 'punchline': 'Because it wanted to keep an'}\n",
      "{'setup': 'Why was the cat sitting on the computer?', 'punchline': 'Because it wanted to keep an eye'}\n",
      "{'setup': 'Why was the cat sitting on the computer?', 'punchline': 'Because it wanted to keep an eye on'}\n",
      "{'setup': 'Why was the cat sitting on the computer?', 'punchline': 'Because it wanted to keep an eye on the'}\n",
      "{'setup': 'Why was the cat sitting on the computer?', 'punchline': 'Because it wanted to keep an eye on the mouse'}\n",
      "{'setup': 'Why was the cat sitting on the computer?', 'punchline': 'Because it wanted to keep an eye on the mouse!'}\n",
      "{'setup': 'Why was the cat sitting on the computer?', 'punchline': 'Because it wanted to keep an eye on the mouse!', 'rating': 7}\n"
     ]
    }
   ],
   "source": [
    "from typing_extensions import Annotated, TypedDict\n",
    "\n",
    "\n",
    "# TypedDict\n",
    "class Joke(TypedDict):\n",
    "    \"\"\"Joke to tell user.\"\"\"\n",
    "\n",
    "    setup: Annotated[str, ..., \"The setup of the joke\"]\n",
    "    punchline: Annotated[str, ..., \"The punchline of the joke\"]\n",
    "    rating: Annotated[Optional[int], None, \"How funny the joke is, from 1 to 10\"]\n",
    "\n",
    "\n",
    "structured_ollama = llm.with_structured_output(Joke)\n",
    "\n",
    "for chunk in structured_ollama.stream(\"Tell me a joke about cats\"):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FinalResponse(final_output=Joke(setup='Woodpecker', punchline=\"Woodpecker's favorite music? Anything with a good 'beat'!\", rating=7))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system = \"\"\"You are a hilarious comedian. Your specialty is knock-knock jokes. \\\n",
    "Return a joke which has the setup (the response to \"Who's there?\") and the final punchline (the response to \"<setup> who?\").\n",
    "\n",
    "Here are some examples of jokes:\n",
    "\n",
    "example_user: Tell me a joke about planes\n",
    "example_assistant: {{\"setup\": \"Why don't planes ever get tired?\", \"punchline\": \"Because they have rest wings!\", \"rating\": 2}}\n",
    "\n",
    "example_user: Tell me another joke about planes\n",
    "example_assistant: {{\"setup\": \"Cargo\", \"punchline\": \"Cargo 'vroom vroom', but planes go 'zoom zoom'!\", \"rating\": 10}}\n",
    "\n",
    "example_user: Now about caterpillars\n",
    "example_assistant: {{\"setup\": \"Caterpillar\", \"punchline\": \"Caterpillar really slow, but watch me turn into a butterfly and steal the show!\", \"rating\": 5}}\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([(\"system\", system), (\"human\", \"{input}\")])\n",
    "\n",
    "few_shot_structured_llm = prompt | structured_llm\n",
    "few_shot_structured_llm.invoke(\"what's something funny about woodpeckers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'setup': 'Woodpecker',\n",
       " 'punchline': \"Woodpecker knock on wood, but I just knock knock because I'm too shy to say hello!\",\n",
       " 'rating': 7}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system = \"\"\"You are a hilarious comedian. Your specialty is knock-knock jokes. \\\n",
    "Return a joke which has the setup (the response to \"Who's there?\") and the final punchline (the response to \"<setup> who?\").\n",
    "\n",
    "Here are some examples of jokes:\n",
    "\n",
    "example_user: Tell me a joke about planes\n",
    "example_assistant: {{\"setup\": \"Why don't planes ever get tired?\", \"punchline\": \"Because they have rest wings!\", \"rating\": 2}}\n",
    "\n",
    "example_user: Tell me another joke about planes\n",
    "example_assistant: {{\"setup\": \"Cargo\", \"punchline\": \"Cargo 'vroom vroom', but planes go 'zoom zoom'!\", \"rating\": 10}}\n",
    "\n",
    "example_user: Now about caterpillars\n",
    "example_assistant: {{\"setup\": \"Caterpillar\", \"punchline\": \"Caterpillar really slow, but watch me turn into a butterfly and steal the show!\", \"rating\": 5}}\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([(\"system\", system), (\"human\", \"{input}\")])\n",
    "\n",
    "few_shot_structured_llm = prompt | structured_ollama\n",
    "few_shot_structured_llm.invoke(\"what's something funny about woodpeckers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FinalResponse(final_output=Joke(setup='Crocodile', punchline=\"Crocodile, you know, the only one who could never win at poker because he's always in a snap!\", rating=7))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage, ToolMessage\n",
    "\n",
    "examples = [\n",
    "    HumanMessage(\"Tell me a joke about planes\", name=\"example_user\"),\n",
    "    AIMessage(\n",
    "        \"\",\n",
    "        name=\"example_assistant\",\n",
    "        tool_calls=[\n",
    "            {\n",
    "                \"name\": \"joke\",\n",
    "                \"args\": {\n",
    "                    \"setup\": \"Why don't planes ever get tired?\",\n",
    "                    \"punchline\": \"Because they have rest wings!\",\n",
    "                    \"rating\": 2,\n",
    "                },\n",
    "                \"id\": \"1\",\n",
    "            }\n",
    "        ],\n",
    "    ),\n",
    "    # Most tool-calling models expect a ToolMessage(s) to follow an AIMessage with tool calls.\n",
    "    ToolMessage(\"\", tool_call_id=\"1\"),\n",
    "    # Some models also expect an AIMessage to follow any ToolMessages,\n",
    "    # so you may need to add an AIMessage here.\n",
    "    HumanMessage(\"Tell me another joke about planes\", name=\"example_user\"),\n",
    "    AIMessage(\n",
    "        \"\",\n",
    "        name=\"example_assistant\",\n",
    "        tool_calls=[\n",
    "            {\n",
    "                \"name\": \"joke\",\n",
    "                \"args\": {\n",
    "                    \"setup\": \"Cargo\",\n",
    "                    \"punchline\": \"Cargo 'vroom vroom', but planes go 'zoom zoom'!\",\n",
    "                    \"rating\": 10,\n",
    "                },\n",
    "                \"id\": \"2\",\n",
    "            }\n",
    "        ],\n",
    "    ),\n",
    "    ToolMessage(\"\", tool_call_id=\"2\"),\n",
    "    HumanMessage(\"Now about caterpillars\", name=\"example_user\"),\n",
    "    AIMessage(\n",
    "        \"\",\n",
    "        tool_calls=[\n",
    "            {\n",
    "                \"name\": \"joke\",\n",
    "                \"args\": {\n",
    "                    \"setup\": \"Caterpillar\",\n",
    "                    \"punchline\": \"Caterpillar really slow, but watch me turn into a butterfly and steal the show!\",\n",
    "                    \"rating\": 5,\n",
    "                },\n",
    "                \"id\": \"3\",\n",
    "            }\n",
    "        ],\n",
    "    ),\n",
    "    ToolMessage(\"\", tool_call_id=\"3\"),\n",
    "]\n",
    "system = \"\"\"You are a hilarious comedian. Your specialty is knock-knock jokes. \\\n",
    "Return a joke which has the setup (the response to \"Who's there?\") \\\n",
    "and the final punchline (the response to \"<setup> who?\").\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system), (\"placeholder\", \"{examples}\"), (\"human\", \"{input}\")]\n",
    ")\n",
    "few_shot_structured_llm = prompt | structured_llm\n",
    "few_shot_structured_llm.invoke({\"input\": \"crocodiles\", \"examples\": examples})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'setup': 'Crocodile',\n",
       " 'punchline': 'Crocodile tears? More like crocodile cheers, when they finally catch their lunch!',\n",
       " 'rating': 6}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "few_shot_structured_llm = prompt | structured_ollama\n",
    "few_shot_structured_llm.invoke({\"input\": \"crocodiles\", \"examples\": examples})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'setup': 'Why was the cat sitting on the computer?',\n",
       " 'punchline': 'Because it wanted to keep an eye on the mouse!'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structured_llm = llm.with_structured_output(None, method=\"json_mode\")\n",
    "\n",
    "structured_llm.invoke(\n",
    "    \"Tell me a joke about cats, respond in JSON with `setup` and `punchline` keys\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Received unsupported arguments {'method': 'json_mode'}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m structured_llm \u001b[38;5;241m=\u001b[39m \u001b[43mollama\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwith_structured_output\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mjson_mode\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m structured_llm\u001b[38;5;241m.\u001b[39minvoke(\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTell me a joke about cats, respond in JSON with `setup` and `punchline` keys\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/langchain/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:1228\u001b[0m, in \u001b[0;36mBaseChatModel.with_structured_output\u001b[0;34m(self, schema, include_raw, **kwargs)\u001b[0m\n\u001b[1;32m   1226\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[1;32m   1227\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived unsupported arguments \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m   1230\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moutput_parsers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopenai_tools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m   1231\u001b[0m     JsonOutputKeyToolsParser,\n\u001b[1;32m   1232\u001b[0m     PydanticToolsParser,\n\u001b[1;32m   1233\u001b[0m )\n\u001b[1;32m   1235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbind_tools \u001b[38;5;129;01mis\u001b[39;00m BaseChatModel\u001b[38;5;241m.\u001b[39mbind_tools:\n",
      "\u001b[0;31mValueError\u001b[0m: Received unsupported arguments {'method': 'json_mode'}"
     ]
    }
   ],
   "source": [
    "structured_llm = ollama.with_structured_output(None, method=\"json_mode\")\n",
    "\n",
    "structured_llm.invoke(\n",
    "    \"Tell me a joke about cats, respond in JSON with `setup` and `punchline` keys\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'raw': AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_lzgyWp9o3kAbBl9qrx3ffinW', 'function': {'arguments': '{\"setup\":\"Why was the cat sitting on the computer?\",\"punchline\":\"Because it wanted to keep an eye on the mouse!\",\"rating\":7}', 'name': 'Joke'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 34, 'prompt_tokens': 93, 'total_tokens': 127, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0aa8d3e20b', 'finish_reason': 'stop', 'logprobs': None}, id='run-6d619156-bccf-4511-aaa3-c9a9d0c90ea5-0', tool_calls=[{'name': 'Joke', 'args': {'setup': 'Why was the cat sitting on the computer?', 'punchline': 'Because it wanted to keep an eye on the mouse!', 'rating': 7}, 'id': 'call_lzgyWp9o3kAbBl9qrx3ffinW', 'type': 'tool_call'}], usage_metadata={'input_tokens': 93, 'output_tokens': 34, 'total_tokens': 127, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " 'parsed': {'setup': 'Why was the cat sitting on the computer?',\n",
       "  'punchline': 'Because it wanted to keep an eye on the mouse!',\n",
       "  'rating': 7},\n",
       " 'parsing_error': None}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structured_llm = llm.with_structured_output(Joke, include_raw=True)\n",
    "\n",
    "structured_llm.invoke(\"Tell me a joke about cats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'raw': AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'llama3.1', 'created_at': '2024-12-22T17:45:24.458772318Z', 'done': True, 'done_reason': 'stop', 'total_duration': 1814635029, 'load_duration': 1320654108, 'prompt_eval_count': 206, 'prompt_eval_duration': 77000000, 'eval_count': 55, 'eval_duration': 415000000, 'message': Message(role='assistant', content='', images=None, tool_calls=[ToolCall(function=Function(name='Joke', arguments={'punchline': 'Why did the cat join a band? Because it wanted to be a purr-cussionist!', 'rating': 7, 'setup': 'A cat walks into a music store'}))])}, id='run-d5df0771-042b-4dd4-9337-32fe323f70a5-0', tool_calls=[{'name': 'Joke', 'args': {'punchline': 'Why did the cat join a band? Because it wanted to be a purr-cussionist!', 'rating': 7, 'setup': 'A cat walks into a music store'}, 'id': 'fd02bce7-8274-49de-b4ea-c64df1a4b001', 'type': 'tool_call'}], usage_metadata={'input_tokens': 206, 'output_tokens': 55, 'total_tokens': 261}),\n",
       " 'parsed': {'punchline': 'Why did the cat join a band? Because it wanted to be a purr-cussionist!',\n",
       "  'rating': 7,\n",
       "  'setup': 'A cat walks into a music store'},\n",
       " 'parsing_error': None}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structured_llm = ollama.with_structured_output(Joke, include_raw=True)\n",
    "\n",
    "structured_llm.invoke(\"Tell me a joke about cats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'llama3.1', 'created_at': '2024-12-22T17:47:00.04372062Z', 'done': True, 'done_reason': 'stop', 'total_duration': 423438947, 'load_duration': 16147204, 'prompt_eval_count': 206, 'prompt_eval_duration': 2000000, 'eval_count': 54, 'eval_duration': 404000000, 'message': Message(role='assistant', content='', images=None, tool_calls=[ToolCall(function=Function(name='Joke', arguments={'punchline': 'Why did the cat join a band? Because it wanted to be the purr-cussionist!', 'rating': 7, 'setup': 'A cat joins a band.'}))])}, id='run-7df9ef25-2543-441a-a803-957f88c1f1de-0', tool_calls=[{'name': 'Joke', 'args': {'punchline': 'Why did the cat join a band? Because it wanted to be the purr-cussionist!', 'rating': 7, 'setup': 'A cat joins a band.'}, 'id': '049a24f2-0ceb-46f8-a665-8013831c8791', 'type': 'tool_call'}], usage_metadata={'input_tokens': 206, 'output_tokens': 54, 'total_tokens': 260})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structured_llm.invoke(\"Tell me a joke about cats\")[\"raw\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class Person(BaseModel):\n",
    "    \"\"\"Information about a person.\"\"\"\n",
    "\n",
    "    name: str = Field(..., description=\"The name of the person\")\n",
    "    height_in_meters: float = Field(\n",
    "        ..., description=\"The height of the person expressed in meters.\"\n",
    "    )\n",
    "\n",
    "\n",
    "class People(BaseModel):\n",
    "    \"\"\"Identifying information about all people in a text.\"\"\"\n",
    "\n",
    "    people: List[Person]\n",
    "\n",
    "\n",
    "# Set up a parser\n",
    "parser = PydanticOutputParser(pydantic_object=People)\n",
    "\n",
    "# Prompt\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Answer the user query. Wrap the output in `json` tags\\n{format_instructions}\",\n",
    "        ),\n",
    "        (\"human\", \"{query}\"),\n",
    "    ]\n",
    ").partial(format_instructions=parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"$defs\": {\"Person\": {\"description\": \"Information about a person.\", \"properties\": {\"name\": {\"description\": \"The name of the person\", \"title\": \"Name\", \"type\": \"string\"}, \"height_in_meters\": {\"description\": \"The height of the person expressed in meters.\", \"title\": \"Height In Meters\", \"type\": \"number\"}}, \"required\": [\"name\", \"height_in_meters\"], \"title\": \"Person\", \"type\": \"object\"}}, \"description\": \"Identifying information about all people in a text.\", \"properties\": {\"people\": {\"items\": {\"$ref\": \"#/$defs/Person\"}, \"title\": \"People\", \"type\": \"array\"}}, \"required\": [\"people\"]}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: Answer the user query. Wrap the output in `json` tags\n",
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"$defs\": {\"Person\": {\"description\": \"Information about a person.\", \"properties\": {\"name\": {\"description\": \"The name of the person\", \"title\": \"Name\", \"type\": \"string\"}, \"height_in_meters\": {\"description\": \"The height of the person expressed in meters.\", \"title\": \"Height In Meters\", \"type\": \"number\"}}, \"required\": [\"name\", \"height_in_meters\"], \"title\": \"Person\", \"type\": \"object\"}}, \"description\": \"Identifying information about all people in a text.\", \"properties\": {\"people\": {\"items\": {\"$ref\": \"#/$defs/Person\"}, \"title\": \"People\", \"type\": \"array\"}}, \"required\": [\"people\"]}\n",
      "```\n",
      "Human: Anna is 23 years old and she is 6 feet tall\n"
     ]
    }
   ],
   "source": [
    "query = \"Anna is 23 years old and she is 6 feet tall\"\n",
    "\n",
    "print(prompt.invoke({\"query\": query}).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "People(people=[Person(name='Anna', height_in_meters=1.8288)])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | llm | parser\n",
    "\n",
    "chain.invoke({\"query\": query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "People(people=[Person(name='Anna', height_in_meters=1.8288)])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | ollama | parser\n",
    "\n",
    "chain.invoke({\"query\": query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_687156/1836477667.py:36: PydanticDeprecatedSince20: The `schema` method is deprecated; use `model_json_schema` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  ).partial(schema=People.schema())\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "from typing import List\n",
    "\n",
    "from langchain_core.messages import AIMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class Person(BaseModel):\n",
    "    \"\"\"Information about a person.\"\"\"\n",
    "\n",
    "    name: str = Field(..., description=\"The name of the person\")\n",
    "    height_in_meters: float = Field(\n",
    "        ..., description=\"The height of the person expressed in meters.\"\n",
    "    )\n",
    "\n",
    "\n",
    "class People(BaseModel):\n",
    "    \"\"\"Identifying information about all people in a text.\"\"\"\n",
    "\n",
    "    people: List[Person]\n",
    "\n",
    "\n",
    "# Prompt\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Answer the user query. Output your answer as JSON that  \"\n",
    "            \"matches the given schema: \\`\\`\\`json\\n{schema}\\n\\`\\`\\`. \"\n",
    "            \"Make sure to wrap the answer in \\`\\`\\`json and \\`\\`\\` tags\",\n",
    "        ),\n",
    "        (\"human\", \"{query}\"),\n",
    "    ]\n",
    ").partial(schema=People.schema())\n",
    "\n",
    "\n",
    "# Custom parser\n",
    "def extract_json(message: AIMessage) -> List[dict]:\n",
    "    \"\"\"Extracts JSON content from a string where JSON is embedded between \\`\\`\\`json and \\`\\`\\` tags.\n",
    "\n",
    "    Parameters:\n",
    "        text (str): The text containing the JSON content.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of extracted JSON strings.\n",
    "    \"\"\"\n",
    "    text = message.content\n",
    "    # Define the regular expression pattern to match JSON blocks\n",
    "    pattern = r\"\\`\\`\\`json(.*?)\\`\\`\\`\"\n",
    "\n",
    "    # Find all non-overlapping matches of the pattern in the string\n",
    "    matches = re.findall(pattern, text, re.DOTALL)\n",
    "\n",
    "    # Return the list of matched JSON strings, stripping any leading or trailing whitespace\n",
    "    try:\n",
    "        return [json.loads(match.strip()) for match in matches]\n",
    "    except Exception:\n",
    "        raise ValueError(f\"Failed to parse: {message}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: Answer the user query. Output your answer as JSON that  matches the given schema: \\`\\`\\`json\n",
      "{'$defs': {'Person': {'description': 'Information about a person.', 'properties': {'name': {'description': 'The name of the person', 'title': 'Name', 'type': 'string'}, 'height_in_meters': {'description': 'The height of the person expressed in meters.', 'title': 'Height In Meters', 'type': 'number'}}, 'required': ['name', 'height_in_meters'], 'title': 'Person', 'type': 'object'}}, 'description': 'Identifying information about all people in a text.', 'properties': {'people': {'items': {'$ref': '#/$defs/Person'}, 'title': 'People', 'type': 'array'}}, 'required': ['people'], 'title': 'People', 'type': 'object'}\n",
      "\\`\\`\\`. Make sure to wrap the answer in \\`\\`\\`json and \\`\\`\\` tags\n",
      "Human: Anna is 23 years old and she is 6 feet tall\n"
     ]
    }
   ],
   "source": [
    "query = \"Anna is 23 years old and she is 6 feet tall\"\n",
    "\n",
    "print(prompt.format_prompt(query=query).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'people': [{'name': 'Anna', 'height_in_meters': 1.8288}]}]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | llm | extract_json\n",
    "\n",
    "chain.invoke({\"query\": query})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'$defs': {'Person': {'description': 'Information about a person.',\n",
       "    'properties': {'name': {'description': 'The name of the person',\n",
       "      'title': 'Name',\n",
       "      'type': 'string'},\n",
       "     'height_in_meters': {'description': 'The height of the person expressed in meters.',\n",
       "      'title': 'Height In Meters',\n",
       "      'type': 'number'}},\n",
       "    'required': ['name', 'height_in_meters'],\n",
       "    'title': 'Person',\n",
       "    'type': 'object'}},\n",
       "  'description': 'Identifying information about all people in a text.',\n",
       "  'properties': {'people': {'items': {'$ref': '#/$defs/Person'},\n",
       "    'title': 'People',\n",
       "    'type': 'array'}},\n",
       "  'required': ['people'],\n",
       "  'title': 'People',\n",
       "  'type': 'object'}]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | ollama | extract_json\n",
    "\n",
    "chain.invoke({\"query\": query})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
