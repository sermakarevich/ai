{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangChain's document loaders are designed to load document objects from various data sources. They provide a standardized interface for accessing data, regardless of the source.\n",
    "\n",
    "**Key Features of Document Loaders:**\n",
    "\n",
    "*   **Integration**: LangChain offers numerous integrations with various data sources, including Slack, Notion, and Google Drive. You can find a full list of available integrations on the Document loaders integrations page.\n",
    "*   **Interface**: All document loaders implement the `BaseLoader` interface, ensuring a consistent way to load data.\n",
    "*   **Loading Methods**:\n",
    "    *   The `.load()` method is used to load all documents at once.\n",
    "    *   The `.lazy_load()` method is used to load documents one at a time, which can be more efficient when working with large datasets.\n",
    "*   **Custom Parameters**: Each document loader may have specific parameters. For example, a `CSVLoader` would have parameters relevant to loading CSV files.\n",
    "\n",
    "**Example Usage**:\n",
    "\n",
    "The following Python code demonstrates the basic use of a document loader:\n",
    "```python\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "loader = CSVLoader(\n",
    "    # <-- Integration specific parameters here\n",
    ")\n",
    "data = loader.load()\n",
    "for document in loader.lazy_load():\n",
    "    print(document)\n",
    "```\n",
    "**Key methods**:\n",
    "*   `.load()`: This method will load all the documents at once\n",
    "*   `.lazy_load()`: This method will return a generator of documents that is loaded lazily\n",
    "\n",
    "**Additional Resources**:\n",
    "\n",
    "*   How-to guides for document loaders\n",
    "*   Document API reference\n",
    "*   Document loaders integrations\n",
    "\n",
    "In summary, document loaders in LangChain provide a **flexible and unified way to load data** from various sources. Whether you are working with small or large datasets, LangChain provides loading methods that meet the needs of your project.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../../llama/f6ed1f19-48dd-4ef9-a8df-0b31119829e7.csv\n",
      "../../../../llama/202411040454.csv\n",
      "../../../../llama/676bf4a6-ab18-4cb0-ae00-80ccc225f6d7.csv\n",
      "../../../../llama/covenanthealth/20241104_covenanthealth_chatgpt_predictions_with_mac_info.csv.gzip\n",
      "../../../../llama/covenanthealth/20241104_covenanthealth_chatgpt_96_accuracy.csv.gzip\n",
      "../../../../llama/covenanthealth/20241104_covenanthealth_chgpt_predictions.csv.gzip\n",
      "../../../../llama/covenanthealth/20241104_covenanthealth_chatgpt_predictions_no_mac_info.csv.gzip\n",
      "../../../../llama/covenanthealth/covenanthealth.csv\n",
      "../../../../llm_prompt_recovery/datasets/sources.csv\n",
      "../../../../llm_prompt_recovery/datasets/datasets/sources.csv\n",
      "../../../../llm_prompt_recovery/datasets/datasets/persuade_chatgpt_responses_4090.csv\n",
      "../../../../llm_prompt_recovery/datasets/datasets/writeprompts_chatgpt_responses_4090.csv\n",
      "../../../../llm_prompt_recovery/datasets/datasets/persuade_chatgpt_responses_1080.csv\n",
      "../../../../llm_prompt_recovery/datasets/datasets/persuade_chatgpt_responses_dlbox.csv\n",
      "../../../../llm_prompt_recovery/datasets/datasets/nbroad-v2.csv\n",
      "../../../../llm_prompt_recovery/datasets/datasets/persuade_corpus_1.0.csv\n",
      "../../../../llm_prompt_recovery/datasets/datasets/nbroad-v1.csv\n",
      "../../../../llm_prompt_recovery/datasets/datasets/writeprompts_dataset.csv\n",
      "../../../../llm_prompt_recovery/datasets/datasets/persuade_2.0_human_scores_demo_id_github.csv\n",
      "../../../../llm_prompt_recovery/datasets/datasets/chatgpt_prompts.csv\n",
      "../../../../llm_prompt_recovery/datasets/persuade_chatgpt_responses_4090.csv\n",
      "../../../../llm_prompt_recovery/datasets/writeprompts_chatgpt_responses_4090.csv\n",
      "../../../../llm_prompt_recovery/datasets/persuade_chatgpt_responses_1080.csv\n",
      "../../../../llm_prompt_recovery/datasets/persuade_chatgpt_responses_dlbox.csv\n",
      "../../../../llm_prompt_recovery/datasets/nbroad-v2.csv\n",
      "../../../../llm_prompt_recovery/datasets/persuade_corpus_1.0.csv\n",
      "../../../../llm_prompt_recovery/datasets/nbroad-v1.csv\n",
      "../../../../llm_prompt_recovery/datasets/writeprompts_dataset.csv\n",
      "../../../../llm_prompt_recovery/datasets/persuade_2.0_human_scores_demo_id_github.csv\n",
      "../../../../llm_prompt_recovery/datasets/chatgpt_prompts.csv\n"
     ]
    }
   ],
   "source": [
    "! find ../../../../ | grep csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '../../../../llm_prompt_recovery/datasets/chatgpt_prompts.csv', 'row': 0}, page_content=\"prompt: Make this into a children's bedtime story\"),\n",
       " Document(metadata={'source': '../../../../llm_prompt_recovery/datasets/chatgpt_prompts.csv', 'row': 1}, page_content='prompt: Rewrite this as a monologue by a tree witnessing centuries of history')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "loader = CSVLoader(\"../../../../llm_prompt_recovery/datasets/chatgpt_prompts.csv\")\n",
    "\n",
    "data = loader.load()\n",
    "data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
