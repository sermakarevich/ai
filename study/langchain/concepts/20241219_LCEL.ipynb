{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangChain Expression Language (LCEL) is a declarative approach to building Runnables, where you describe what should happen rather than how it should happen, allowing LangChain to optimise run-time execution. A Runnable created using LCEL is often referred to as a \"chain\" and it implements the full Runnable Interface.\n",
    "\n",
    "Hereâ€™s a summary of LCEL's key features:\n",
    "\n",
    "*   **Optimised Execution:** LCEL optimises the execution of chains through parallel processing and asynchronous support.\n",
    "    *   It allows for **parallel execution**, which can reduce latency by processing tasks concurrently.\n",
    "    *   It provides **guaranteed asynchronous support**, useful for handling multiple requests concurrently in a server environment.\n",
    "    *   It simplifies **streaming**, optimising output to minimise time-to-first-token.\n",
    "\n",
    "*   **Additional Benefits**:\n",
    "    *   LCEL provides seamless integration with **LangSmith tracing**, logging all steps automatically for better observability and debugging.\n",
    "    *   Chains built with LCEL use a **standard API**, allowing them to be used like any other Runnable.\n",
    "    *   These chains can be **deployed using LangServe** for production use.\n",
    "\n",
    "*   **When to Use LCEL:**\n",
    "    *   LCEL is suitable for simpler orchestration tasks, such as simple chains involving a prompt, LLM, and parser or simple retrieval setups.\n",
    "    *   If you are making a single LLM call, you don't need LCEL; instead call the underlying chat model directly.\n",
    "    *   For complex applications with state management, branching, cycles, or multiple agents, it's recommended to use **LangGraph** instead. However, you can use LCEL within individual nodes in LangGraph.\n",
    "\n",
    "*   **Composition Primitives:** LCEL chains are built by composing existing Runnables, with the main composition primitives being **RunnableSequence** and **RunnableParallel**.\n",
    "    *   **RunnableSequence** chains runnables sequentially, with the output of one serving as the input to the next. The following code:\n",
    "        ```\n",
    "        from langchain_core.runnables import RunnableSequence\n",
    "        chain = RunnableSequence([runnable1, runnable2])\n",
    "        final_output = chain.invoke(some_input)\n",
    "        ```\n",
    "        is equivalent to:\n",
    "        ```\n",
    "        output1 = runnable1.invoke(some_input)\n",
    "        final_output = runnable2.invoke(output1)\n",
    "        ```\n",
    "    *   **RunnableParallel** runs runnables concurrently, providing the same input to each. The following code:\n",
    "    ```\n",
    "    from langchain_core.runnables import RunnableParallel\n",
    "    chain = RunnableParallel({\n",
    "        \"key1\": runnable1,\n",
    "        \"key2\": runnable2,\n",
    "    })\n",
    "    final_output = chain.invoke(some_input)\n",
    "    ```\n",
    "    will yield:\n",
    "    ```\n",
    "    {\n",
    "        \"key1\": runnable1.invoke(some_input),\n",
    "        \"key2\": runnable2.invoke(some_input),\n",
    "    }\n",
    "    ```\n",
    "    The runnables are executed in parallel, resulting in faster execution time. RunnableParallel supports both synchronous (using ThreadPoolExecutor) and asynchronous (using asyncio.gather) execution.\n",
    "*   **Composition Syntax:**\n",
    "    *   The `|` operator is overloaded to create a **RunnableSequence**.\n",
    "        *   `chain = runnable1 | runnable2` is equivalent to `chain = RunnableSequence([runnable1, runnable2])`.\n",
    "    *   The `.pipe` method can be used as an alternative to the `|` operator.\n",
    "        *   `chain = runnable1.pipe(runnable2)` is equivalent to `chain = runnable1 | runnable2`.\n",
    "    *   **Automatic Type Coercion:**\n",
    "        *   A dictionary is automatically converted to a **RunnableParallel** within an LCEL expression. For example:\n",
    "          ```\n",
    "          mapping = {\n",
    "              \"key1\": runnable1,\n",
    "              \"key2\": runnable2,\n",
    "          }\n",
    "          chain = mapping | runnable3\n",
    "          ```\n",
    "          is converted to:\n",
    "          ```\n",
    "          chain = RunnableSequence([RunnableParallel(mapping), runnable3])\n",
    "          ```\n",
    "        *  A function is automatically converted to a **RunnableLambda** within an LCEL expression. For example:\n",
    "           ```\n",
    "           def some_func(x):\n",
    "               return x\n",
    "           chain = some_func | runnable1\n",
    "           ```\n",
    "           is converted to:\n",
    "           ```\n",
    "           chain = RunnableSequence([RunnableLambda(some_func), runnable1])\n",
    "           ```\n",
    "*   **Legacy Chains:** LCEL aims to provide consistency and customisation, unlike legacy chains such as `LLMChain` and `ConversationalRetrievalChain`. It's recommended to migrate from these legacy chains to LCEL for better customisation and clarity.\n",
    "\n",
    "In summary, LCEL offers a powerful way to build and optimise LangChain applications through its declarative approach, composition primitives, and shorthand syntax. It also provides enhanced performance through parallel processing, asynchronous support, and seamless streaming capabilities. It is suited for simple orchestration tasks and can be used within individual nodes of LangGraph for complex applications.\n",
    "\n",
    "It is worth noting that the streaming capabilities discussed in our previous conversation related to LangChain more generally and applies to LCEL, as LCEL chains can be streamed, allowing for incremental output as the chain is executed, which is useful to reduce the time-to-first-token.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runnable1 - Current datetime: 2024-12-19 06:50:23.286430\n",
      "Runnable2 - Current datetime: 2024-12-19 06:50:23.287213\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Output from runnable2: Output from runnable1: {'foo': 'bar'}\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableSequence, RunnableLambda\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def runnable1(input):\n",
    "    '''Runnable1'''\n",
    "    print(f\"Runnable1 - Current datetime: {datetime.now()}\")\n",
    "    return f\"Output from runnable1: {input}\"\n",
    "\n",
    "\n",
    "def runnable2(input):\n",
    "    '''Runnable2'''\n",
    "    print(f\"Runnable2 - Current datetime: {datetime.now()}\")\n",
    "    return f\"Output from runnable2: {input}\"\n",
    "\n",
    "# runnable1 = RunnableLambda(runnable1)\n",
    "# runnable2 = RunnableLambda(runnable2)\n",
    "\n",
    "chain = RunnableSequence(runnable1, runnable2)\n",
    "chain.invoke({\"foo\": \"bar\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runnable1 - Current datetime: 2024-12-19 06:50:54.363559\n",
      "Runnable2 - Current datetime: 2024-12-19 06:50:54.363851\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'key1': \"Output from runnable1: {'foo': 'bar'}\",\n",
       " 'key2': \"Output from runnable2: {'foo': 'bar'}\"}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "chain = RunnableParallel({\n",
    "    \"key1\": runnable1,\n",
    "    \"key2\": runnable2,\n",
    "})\n",
    "chain.invoke({\"foo\": \"bar\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runnable1 - Current datetime: 2024-12-19 07:01:10.240102\n",
      "Runnable2 - Current datetime: 2024-12-19 07:01:10.240217\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Output from runnable2: Output from runnable1: {'foo': 'bar'}\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runnable1 = RunnableLambda(runnable1)\n",
    "runnable2 = RunnableLambda(runnable2)\n",
    "\n",
    "chain = runnable1.pipe(runnable2)\n",
    "\n",
    "chain.invoke({\"foo\": \"bar\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runnable1 - Current datetime: 2024-12-19 07:01:53.332872\n",
      "Runnable2 - Current datetime: 2024-12-19 07:01:53.332998\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Output from runnable2: Output from runnable1: {'foo': 'bar'}\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = runnable1 | runnable2\n",
    "\n",
    "chain.invoke({\"foo\": \"bar\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runnable1 - Current datetime: 2024-12-19 07:03:47.368899\n",
      "Runnable2 - Current datetime: 2024-12-19 07:03:47.369949\n",
      "Runnable3 - Current datetime: 2024-12-19 07:03:47.371110\n",
      "Output from runnable3: {'key1': \"Output from runnable1: {'foo': 'bar'}\", 'key2': \"Output from runnable2: {'foo': 'bar'}\"}\n"
     ]
    }
   ],
   "source": [
    "# Inside an LCEL expression, a dictionary is automatically converted to a RunnableParallel.\n",
    "\n",
    "def runnable3(input):\n",
    "    '''Runnable3'''\n",
    "    print(f\"Runnable3 - Current datetime: {datetime.now()}\")\n",
    "    return f\"Output from runnable3: {input}\"\n",
    "\n",
    "runnable3 = RunnableLambda(runnable3)\n",
    "\n",
    "mapping = {\n",
    "    \"key1\": runnable1,\n",
    "    \"key2\": runnable2,\n",
    "}\n",
    "\n",
    "chain = mapping | runnable3\n",
    "\n",
    "print(chain.invoke({\"foo\": \"bar\"}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runnable1 - Current datetime: 2024-12-19 07:04:58.797097\n",
      "Runnable2 - Current datetime: 2024-12-19 07:04:58.797477\n",
      "Runnable3 - Current datetime: 2024-12-19 07:04:58.797785\n",
      "Output from runnable3: {'key1': \"Output from runnable1: {'foo': 'bar'}\", 'key2': \"Output from runnable2: {'foo': 'bar'}\"}\n"
     ]
    }
   ],
   "source": [
    "chain = RunnableSequence(RunnableParallel(mapping), runnable3)\n",
    "\n",
    "print(chain.invoke({\"foo\": \"bar\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
