{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Overview**\n",
    "\n",
    "*   The **Runnable interface** is a foundational component in LangChain, providing a consistent way to interact with various LangChain elements such as language models, output parsers, retrievers, and compiled LangGraph graphs.\n",
    "*   It defines a standard interface that allows a component to be invoked, batched, streamed, inspected and composed.\n",
    "\n",
    "**Key Features**\n",
    "\n",
    "*   **Invocation**: A single input is transformed into an output.\n",
    "*   **Batching**: Multiple inputs are efficiently transformed into outputs in parallel.\n",
    "    *   `batch`: Processes multiple inputs in parallel and returns results in the same order as inputs.\n",
    "    *   `batch_as_completed`: Processes multiple inputs in parallel and returns results as they complete, potentially out of order, but including the input index.\n",
    "    *  The default implementation uses a thread pool executor to run the `invoke` method in parallel, which is beneficial for I/O-bound operations but less effective for CPU-bound operations due to Python's GIL. Some Runnables may provide optimized implementations for their use cases.\n",
    "    *   The `max_concurrency` attribute in `RunnableConfig` can be used to control the maximum number of parallel calls when using `batch` or `batch_as_completed`.\n",
    "*   **Streaming**: Outputs are streamed as they are produced, enhancing responsiveness.\n",
    "    *   Sync `stream` and async `astream`: Yields the output of a Runnable as it is generated.\n",
    "    *   Async `astream_events`: A more advanced API that streams intermediate steps and final output.\n",
    "    *   Legacy async `astream_log`: A legacy streaming API that streams intermediate steps and final output.\n",
    "*   **Inspection**: Allows access to schematic information about a Runnable's input, output, and configuration. This includes the ability to get the JSON Schema or Pydantic schemas of the input, output, and configuration options.\n",
    "*   **Composition**: Multiple Runnables can be composed using the LangChain Expression Language (LCEL) to create complex pipelines.\n",
    "\n",
    "**Asynchronous Support**\n",
    "\n",
    "*   Runnables offer an asynchronous API, enabling calls using the `await` syntax in Python.\n",
    "*   Asynchronous methods are identified with an \"a\" prefix (e.g., `ainvoke`, `abatch`, `astream`, `abatch_as_completed`).\n",
    "*   Async versions of batch methods (`abatch` and `abatch_as_completed`) use `asyncio` to run `ainvoke` in parallel.\n",
    "\n",
    "**Input and Output Types**\n",
    "\n",
    "*   Each Runnable is defined by its input and output types, which can be any Python object.\n",
    "*   The input and output types vary depending on the component:\n",
    "    *   Prompt: Input is a dictionary; output is a `PromptValue`.\n",
    "    *   ChatModel: Input is a string, list of chat messages or a `PromptValue`; output is a `ChatMessage`.\n",
    "    *   LLM: Input is a string, list of chat messages or a `PromptValue`; output is a String.\n",
    "    *   OutputParser: Input is the output of an LLM or ChatModel; output depends on the parser.\n",
    "    *   Retriever: Input is a string; output is a list of documents.\n",
    "    *   Tool: Input is a string or dictionary; output depends on the tool.\n",
    "*   LangChain attempts to automatically infer input and output types, but for complex Runnables composed using LCEL, overriding these types using the `with_types` method is recommended.\n",
    "\n",
    "**RunnableConfig**\n",
    "\n",
    "*   The `RunnableConfig` is a dictionary passed as a second argument to execution methods (e.g., `invoke`, `batch`, `stream`, `astream_events`), which allows runtime configuration.\n",
    "*   It can include the following attributes:\n",
    "    *   `run_name`: A custom name for the run (not inherited by sub-calls).\n",
    "    *   `run_id`: A unique identifier for the call.\n",
    "    *   `tags`: Tags for the call and sub-calls.\n",
    "    *   `metadata`: Metadata for the call and sub-calls.\n",
    "    *   `callbacks`: Callbacks for the call and sub-calls.\n",
    "    *   `max_concurrency`: Maximum number of parallel calls to make, used by `batch`.\n",
    "    *   `recursion_limit`: Maximum number of times a call can recurse.\n",
    "    *   `configurable`: Runtime values for configurable attributes of the Runnable.\n",
    "*   The `RunnableConfig` is automatically propagated to sub-calls in most cases. However, in Python 3.9 and 3.10 with async code, manual propagation is required.\n",
    "\n",
    "**Custom Runnables**\n",
    "\n",
    "*   Custom Runnables can be created from functions using `RunnableLambda` for simple transformations without streaming, or `RunnableGenerator` for more complex transformations that require streaming.\n",
    "*   Subclassing Runnables to create custom Runnables is discouraged as it is complex and error-prone.\n",
    "\n",
    "**Configurable Runnables**\n",
    "\n",
    "*   Configurable Runnables allow for runtime configuration of attributes and alternatives of Runnables, mainly used for experimentation and exposure to end-users.\n",
    "*   `configurable_fields`: Configures specific attributes of a Runnable.\n",
    "*   `configurable_alternatives`: Specifies alternative Runnables to be used during runtime.\n",
    "\n",
    "This summary covers the main concepts and methods of the Runnable interface as described in the provided document.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
