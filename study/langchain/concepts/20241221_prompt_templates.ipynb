{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an extensive summary in markdown format, drawing on the provided sources, our conversation history, and with some bolding to highlight key concepts:\n",
    "\n",
    "**Prompt Templates**\n",
    "\n",
    "*   **Purpose**: Prompt templates are used to transform user input and parameters into instructions for a language model. This process guides the model's response by helping it understand the context and generate relevant and coherent language-based output.\n",
    "*   **Input**: Prompt templates accept a dictionary as input, where each key corresponds to a variable within the prompt template.\n",
    "*   **Output**: They produce a `PromptValue`, which can be used with LLMs or ChatModels, or converted to a string or list of messages. The purpose of `PromptValue` is to simplify switching between strings and messages.\n",
    "*  **Types of Prompt Templates**:\n",
    "    *   **String Prompt Templates**:\n",
    "        *   These templates are for formatting single strings and are typically used for simpler inputs.\n",
    "        *   Example: A `PromptTemplate` can be created using `from_template` to generate a joke based on a given topic.\n",
    "    *   **Chat Prompt Templates**:\n",
    "        *   These templates are used for formatting lists of messages and consist of a list of templates.\n",
    "        *   Example: A `ChatPromptTemplate` can construct multiple messages, like a system message and a user message, with user-provided variables to format the user message.\n",
    "*   **MessagesPlaceholder**:\n",
    "    *   This template is used to insert a list of messages into a specific location within a prompt template.\n",
    "    *   It allows users to pass a list of messages that can be incorporated into a prompt.\n",
    "    *   Example: When used within a `ChatPromptTemplate`, it can add a system message and a list of `HumanMessage` objects provided by the user.\n",
    "    *   An alternative method is to insert a placeholder string into the `ChatPromptTemplate`.\n",
    "\n",
    "**Key Takeaways**\n",
    "\n",
    "*   Prompt templates are essential for converting user inputs into instructions for language models.\n",
    "*   They handle both simple string formatting (using `StringPromptTemplate`) and more complex message formatting (using `ChatPromptTemplate`).\n",
    "*   `MessagesPlaceholder` and string placeholders within `ChatPromptTemplate` allow for the dynamic insertion of message lists into prompts.\n",
    "\n",
    "This summary covers the key aspects of prompt templates, including their purpose, types, and how they are used with language models, drawing on the provided source material.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringPromptValue(text='Tell me a joke about cats')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\"Tell me a joke about {topic}\")\n",
    "\n",
    "prompt_template.invoke({\"topic\": \"cats\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='You are a helpful just a kid', additional_kwargs={}, response_metadata={}), HumanMessage(content='Tell me a joke about cats', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate([\n",
    "    (\"system\", \"You are a helpful {how_are_you}\"),\n",
    "    (\"user\", \"Tell me a joke about {topic}\")\n",
    "])\n",
    "\n",
    "prompt_template.invoke({\"topic\": \"cats\", \"how_are_you\": \"just a kid\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='You are a helpful assistant', additional_kwargs={}, response_metadata={}), HumanMessage(content='hi!', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "prompt_template = ChatPromptTemplate([\n",
    "    (\"system\", \"You are a helpful assistant\"),\n",
    "    MessagesPlaceholder(\"msgs\")\n",
    "])\n",
    "\n",
    "prompt_template.invoke({\"msgs\": [HumanMessage(content=\"hi!\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='You are a helpful assistant', additional_kwargs={}, response_metadata={}), HumanMessage(content='hi!', additional_kwargs={}, response_metadata={}), AIMessage(content='hello!', additional_kwargs={}, response_metadata={}), HumanMessage(content='Can you help me?', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "prompt_template = ChatPromptTemplate([\n",
    "    (\"system\", \"You are a helpful assistant\"),\n",
    "    MessagesPlaceholder(\"msgs\")\n",
    "])\n",
    "\n",
    "prompt_template.invoke({\"msgs\": [HumanMessage(content=\"hi!\"), AIMessage(content=\"hello!\"), HumanMessage(content=\"Can you help me?\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='You are a helpful assistant', additional_kwargs={}, response_metadata={}), HumanMessage(content='hi!', additional_kwargs={}, response_metadata={}), AIMessage(content='hello!', additional_kwargs={}, response_metadata={}), HumanMessage(content='Can you help me?', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template = ChatPromptTemplate([\n",
    "    (\"system\", \"You are a helpful assistant\"),\n",
    "    (\"placeholder\", \"{msgs}\") # <-- This is the changed part\n",
    "])\n",
    "prompt_template.invoke({\"msgs\": [HumanMessage(content=\"hi!\"), AIMessage(content=\"hello!\"), HumanMessage(content=\"Can you help me?\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
