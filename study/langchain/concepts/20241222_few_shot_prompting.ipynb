{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an extensive summary in markdown format, drawing on the provided sources, our conversation history, and with some bolding to highlight key concepts:\n",
    "\n",
    "**Few-Shot Prompting**\n",
    "\n",
    "*   **Definition:** Few-shot prompting is a technique that improves model performance by providing examples of desired inputs and outputs within the model's prompt. This technique is based on the principle that language models are few-shot learners.\n",
    "*   **Key Considerations**:\n",
    "    *   **Example Generation**: How the examples are created.\n",
    "    *   **Number of Examples**: How many examples are included in each prompt.\n",
    "    *   **Example Selection**: How examples are selected at runtime.\n",
    "    *   **Example Formatting**: How the examples are formatted within the prompt.\n",
    "\n",
    "**1. Generating Examples**\n",
    "\n",
    "*   **Importance:** Creating a good dataset of examples is the first and most important step in few-shot prompting. Good examples should be relevant at runtime, clear, informative, and provide information not already known to the model.\n",
    "*   **Methods for Generating Examples**:\n",
    "    *   **Manual:** Examples are created by people. This is useful for tasks where a small number of core principles must be understood very well.\n",
    "    *   **Better Model:** A better, presumably more expensive model's responses are used as examples for a worse, cheaper model.\n",
    "    *   **User Feedback:** User feedback on interactions is used to generate examples (e.g., positive feedback interactions become examples).\n",
    "    *   **LLM Feedback**: Similar to user feedback, but the process is automated by having models evaluate themselves. This is particularly useful for tasks with a broader and more nuanced range of correct behaviours where automated generation of many examples increases the chances of relevant examples.\n",
    "\n",
    "*   **Single-turn vs. Multi-turn Examples:**\n",
    "    *   **Single-turn examples** consist of a user input and an expected model output.\n",
    "    *   **Multi-turn examples** are entire conversations, where a model initially responds incorrectly and the user corrects it. These are useful for nuanced tasks where common errors need to be shown, including how to correct them.\n",
    "\n",
    "**2. Number of Examples**\n",
    "\n",
    "*   **Trade-off:** More examples generally improve performance, but larger prompts increase costs and latency. Beyond a certain threshold, too many examples can confuse the model.\n",
    "*   **Finding the Right Number:** This is highly dependent on the model, the task, the quality of the examples, and cost and latency constraints.\n",
    "*   **Model Dependence:** Better models typically need fewer examples and quickly reach diminishing returns from adding more.\n",
    "*   **Experimentation:** Running experiments with different numbers of examples is the most reliable way to determine the optimal amount.\n",
    "\n",
    "**3. Selecting Examples**\n",
    "\n",
    "*   **Need for Selection:** Unless the entire dataset is added to each prompt, there must be a way to select examples based on a given input.\n",
    "*   **Selection Methods**:\n",
    "    *   **Randomly**: Examples are selected randomly.\n",
    "    *   **Similarity:** Examples are selected based on semantic or keyword similarity of the inputs.\n",
    "    *   **Other Constraints**: Examples are selected based on token size or other constraints.\n",
    "*   **Tools**: LangChain provides `ExampleSelectors` to facilitate these techniques.\n",
    "*   **Semantic Similarity**: Generally leads to the best model performance, but this is model and task specific. It is important to experiment to assess this.\n",
    "\n",
    "**4. Formatting Examples**\n",
    "\n",
    "*   **Focus on Chat Models:** Most state-of-the-art models are chat models, so formatting examples for these is crucial.\n",
    "*   **Formatting Options:**\n",
    "    *   **System Prompt:** Examples can be inserted as a string in the system prompt. If this method is used, it is important that the syntax clearly defines the start of an example and where the input is as opposed to the output. Different models may respond better to different syntax.\n",
    "    *   **Messages:** Examples can be inserted as their own messages, represented as a sequence of `Human` and `AI` messages. In this case, you may want to assign names to each message (e.g., `example_user`, `example_assistant`).\n",
    "*  **Formatting Tool Call Examples**:\n",
    "    *   **Challenge**: Formatting examples can be tricky when outputs include tool calls, because different models have different constraints on message sequences.\n",
    "    *   **Model-Specific Requirements**: Some models require that `AIMessage` with tool calls be immediately followed by `ToolMessages` for every tool call. Other models additionally require that `ToolMessages` be immediately followed by an `AIMessage` before the next `HumanMessage`. Some also require that tools are passed to the model if there are any tool calls or `ToolMessages`.\n",
    "    *   **Dummy Messages**: If your model requires `ToolMessages` and/or `AIMessages` and your examples only include tool calls and not actual tool outputs, you can add dummy messages with generic contents to satisfy API constraints.\n",
    "    *   **Experimentation**: In cases with dummy messages, itâ€™s worth experimenting with inserting examples as strings versus messages, because dummy messages can negatively affect certain models.\n",
    "\n",
    "**Key Takeaways**\n",
    "\n",
    "*   Few-shot prompting improves model performance by providing examples in the prompt.\n",
    "*   Careful consideration must be given to how to **generate, select, and format** examples, as well as how many are used.\n",
    "*   The best approach is often task and model specific and should be determined through experimentation.\n",
    "*   **Multi-turn examples** can be useful to demonstrate nuanced tasks and corrections.\n",
    "*   Formatting tool call examples requires additional care to follow model-specific message sequence requirements.\n",
    "\n",
    "This summary covers the key aspects of few-shot prompting, including its definition, considerations, and practical guidance, drawing on the provided source material.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
