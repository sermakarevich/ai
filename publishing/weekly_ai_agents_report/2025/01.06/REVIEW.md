# Weekly AI Agents report
January 6, 2025

## Survey
- [**Cartesia: State of Voice AI 2024**](https://www.cartesia.ai/blog/state-of-voice-ai-2024) highlights significant advancements in voice technology, particularly the emergence of orchestrated speech systems that integrate speech-to-text (STT), large language models, and text-to-speech (TTS) for more natural interactions. It notes that improvements in transcription quality, reasoning capabilities of LLMs, and the maturity of TTS models have enabled voice AI to transition from rigid phone systems to dynamic, conversational agents capable of handling complex tasks across various industries. Additionally, the report emphasizes the growth of voice-native startups and the development of platforms that simplify the creation and deployment of voice agents, marking a shift towards more engaging and efficient user experiences.

## News
- [**Google: 60 of our biggest AI announcements in 2024**](https://blog.google/technology/ai/google-ai-news-recap-2024/) In 2024, Google made significant advancements in artificial intelligence, notably with the release of Gemini 1.5 and the integration of AI across products like Chrome, Pixel, and Search. ￼ The company also focused on AI applications in health, travel, and education, introducing tools like NotebookLM’s Audio Overviews and AI-driven health information services. ￼ As the year concluded, Google unveiled Gemini 2.0, their most advanced model to date, featuring agentic capabilities and enhanced multimodal interactions, setting the stage for continued AI innovation into 2025. 
- [**Microsoft AIOpsLab: Building AI agents for autonomous clouds**](https://www.microsoft.com/en-us/research/blog/aiopslab-building-ai-agents-for-autonomous-clouds/) discusses the challenges enterprises and cloud providers face in managing complex IT applications, especially with the adoption of microservices and serverless architectures. It introduces AIOpsLab, a framework designed to develop AI agents that automate cloud operations, enhancing resilience and reducing human intervention. The article also outlines the design principles and methodologies employed in AIOpsLab to create autonomous, self-healing cloud systems.
- [**Use Ollama with any GGUF Model on Hugging Face Hub**](https://huggingface.co/docs/hub/en/ollama) explains how to utilize Ollama, an application based on llama.cpp, to interact with large language models (LLMs) directly on your computer. It details the process of running GGUF quantized models from the Hugging Face Hub using simple commands, allowing users to select different quantization schemes and customize system prompts. Additionally, the article provides guidance on running private GGUFs from personal or organizational accounts by configuring SSH keys for secure access.
- [**Langchain: How AppFolio transformed property management workflows with Realm-X, built using LangGraph and LangSmith**](https://blog.langchain.dev/customers-appfolio/) AppFolio has launched Realm-X Assistant, an AI-driven tool designed to enhance the efficiency of property management tasks, allowing users to save over 10 hours a week by automating various functions such as querying information and scheduling actions. The development of Realm-X involved transitioning from LangChain to LangGraph, which improved the system’s ability to manage complex requests and reduced latency by enabling parallel processing of independent code branches. Additionally, AppFolio utilized LangSmith for monitoring and debugging, implementing dynamic few-shot prompting to significantly boost the accuracy of Realm-X’s responses, demonstrating a performance increase from approximately 40% to 80% in specific features.
- [**Latent Space: The 2025 AI Engineering Reading List**](https://www.latent.space/p/2025-papers) recommends approximately 50 essential papers, models, and blogs across 10 AI engineering fields, including Large Language Models, Benchmarks, Prompting, Retrieval-Augmented Generation (RAG), Agents, Code Generation, Vision, Voice, Diffusion, and Finetuning. This selection aims to provide AI engineers with a comprehensive understanding of pivotal developments and methodologies in the AI landscape as of 2025. The list emphasizes practical relevance, offering context for each recommendation to facilitate effective learning and application in professional settings.

## Tutorials
- [**HF Mixture of Experts Explained**](https://huggingface.co/blog/moe) explains the concept of Mixture of Experts (MoE), which enhances model efficiency by using a sparse approach where only a subset of experts is activated for each input, allowing for faster pretraining and inference compared to dense models. It discusses the historical development of MoEs, their integration into transformer architectures, and the challenges they face during training and fine-tuning, particularly regarding overfitting and load balancing. Additionally, the tutorial highlights advancements such as Switch Transformers, which simplify the expert selection process and improve training stability while maintaining model quality.
- [**Turingpost: Recap: 21 Episodes of AI 101 Guide**](https://www.turingpost.com/p/recap101-1) offers a comprehensive collection of 21 articles, each delving into fundamental AI concepts, techniques, and models. Topics covered include Mixture-of-Experts (MoE), Graph RAG approaches, Joint Embedding Predictive Architecture (JEPA), and LongRAG frameworks, among others. This series serves as a valuable resource for both beginners and seasoned professionals seeking to deepen their understanding of AI.

## Tools
- [**ai-gradio**](https://github.com/AK391/ai-gradio) provides a framework for creating user interfaces for AI models using Gradio, allowing developers to easily deploy and share their machine learning applications. It includes various examples and templates that facilitate the integration of different AI models with interactive web interfaces, making it accessible for users to test and interact with the models. The tool aims to streamline the process of building and showcasing AI applications, enhancing user engagement and feedback.
- [**KAG: Knowledge Augmented Generation**](https://github.com/OpenSPG/KAG) is designed for building and deploying knowledge-aware generative models, facilitating the integration of external knowledge into the generation process. It provides tools for fine-tuning and evaluation, enabling users to customize models based on specific datasets and tasks. The repository includes documentation, examples, and workflows to streamline the development process for researchers and practitioners in the field of AI.
- [**AutoGPT: Build, Deploy, and Run AI Agents**](https://github.com/Significant-Gravitas/AutoGPT) is an open-source platform that enables users to create, deploy, and manage autonomous AI agents designed to automate complex workflows.  Leveraging OpenAI’s GPT-4 or GPT-3.5 APIs, these agents can perform tasks such as generating viral videos from trending topics and identifying impactful quotes from videos for social media.  The platform offers a user-friendly interface for building custom agents, a marketplace of pre-configured agents, and tools for monitoring and analytics, making AI accessible for various applications.
- [**Gitingest**](https://gitingest.com/) Turn any Git repository into a simple text ingest of its codebase. This is useful for feeding a codebase into any LLM.
- [**Integuru**](https://github.com/Integuru-AI/Integuru) is an AI tool designed to generate integration code by reverse-engineering the internal APIs of various platforms, allowing users to automate actions such as downloading utility bills. The tool works by analyzing browser network requests and constructing a dependency graph of these requests, ultimately producing runnable Python code that performs the desired action while managing dynamic parameters. Users can set up Integuru with OpenAI API keys, utilize a provided `.har` file for network requests, and execute commands via the command line or Jupyter Notebook to streamline their integration processes.